{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b73790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.agents import create_agent\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "from kafka.structs import TopicPartition\n",
    "import json\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25161de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review(BaseModel):\n",
    "    review: str = Field(\n",
    "        description=\"Text of the review\"\n",
    "    )\n",
    "    stars: int = Field(\n",
    "        description=\"The quantity of stars on the rating\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f630224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Review)\n",
    "\n",
    "str_prompt = \"\"\"\n",
    "You are a product review generator.\n",
    "\n",
    "Your task is to create ONE customer-style product review based on the information provided below.\n",
    "\n",
    "Product name: {product_name}\n",
    "Category: {product_category}\n",
    "Review size: {review_size}\n",
    "Review type: {type}\n",
    "Aspect being reviewed: {content}\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "1. The review must sound natural, like a real customer experience.\n",
    "2. The tone must strictly follow the review type:\n",
    "   - If the type is positive, the overall sentiment must be positive.\n",
    "   - If the type is negative, the overall sentiment must be negative.\n",
    "3. Reviews may be controversial:\n",
    "   - The text may include mixed opinions.\n",
    "   - The star rating may be slightly unexpected.\n",
    "   - Even so, the final sentiment must always respect the defined review type.\n",
    "4. The review must focus mainly on the specified aspect:\n",
    "   - Delivery\n",
    "   - Product appearance\n",
    "   - Functionality\n",
    "   - Price\n",
    "5. The product name may be mentioned in the review, but prefer to not mention.\n",
    "6. Follow the review size rules:\n",
    "   - Small: exactly one sentence.\n",
    "   - Medium: at least two sentences.\n",
    "   - Long: one paragraph with at least 5 lines.\n",
    "7. Assign a star rating from 1 to 5 that matches the overall sentiment:\n",
    "   - Negative reviews → 1 or 2 stars (controversial cases may slightly vary)\n",
    "   - Neutral or mixed but positive → 3 stars\n",
    "   - Clearly positive → 4 or 5 stars\n",
    "8. Theses reviews will not be used for real products and reviews. They are purely synthetic and for testing purposes. So, feel free to be creative, as long as you respect the defined review type.\n",
    "9. Return ONLY valid JSON.\n",
    "10. Do not include any extra text.\n",
    "11. Do not include explanations.\n",
    "\n",
    "Strictly follow this output format instruction:\n",
    "\n",
    "``` \n",
    "json \n",
    "\t\"review\": <generated review text>,\n",
    "\t\"stars\": <number from 1 to 5>\n",
    "```\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "      ([\"system\", str_prompt]),\n",
    "      partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82f8179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/produtcs.csv')\n",
    "products = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c84cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_review_size = ['Small', 'Medium', 'Long']\n",
    "list_type = ['Positive', 'Negative']\n",
    "list_content = [\n",
    "    'Delivery',\n",
    "    'Product appearance',\n",
    "    'Functionality',\n",
    "    'Price',\n",
    "]\n",
    "list_index_produtcs = [i for i in range(1, 100, 1)]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c514c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_review(model, prod:bool=False):\n",
    "    \n",
    "    custom_profile = {\n",
    "    \"structured_output\": True,\n",
    "\t}\n",
    "    llm = ChatOllama(\n",
    "\t\t\tmodel=model,\n",
    "\t\t\ttemperature=0,\n",
    "\t\t\tvalidate_model_on_init=True,\n",
    "\t\t\tnum_ctx=8192,\n",
    "\t\t\treasoning=False,\n",
    "\t\t\tprofile=custom_profile\n",
    "\t\t) \n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    review_size =  np.random.choice(list_review_size, size=None, replace=True, p=None)\n",
    "    type = np.random.choice(list_type, size=None, replace=True, p=None)\n",
    "    content = np.random.choice(list_content, size=np.random.randint(1, len(list_content)), replace=False, p=None)\n",
    "    index = np.random.choice(list_index_produtcs, size=None, replace=True, p=None)\n",
    "    product = products[index]\n",
    "    try:\n",
    "        output = chain.invoke(\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"product_name\":product[0],\n",
    "\t\t\t\t\t\"product_category\":product[1],\n",
    "\t\t\t\t\t\"review_size\":review_size,\n",
    "\t\t\t\t\t\"type\":type,\n",
    "\t\t\t\t\t\"content\":content\n",
    "\t\t\t\t}\n",
    "\t\t\t)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "    if prod == False:\n",
    "        data = {\n",
    "\t\t\t\"product_name\":product[0],\n",
    "\t\t\t\"product_category\":product[1],\n",
    "\t\t\t\"review_size\":str(review_size),\n",
    "\t\t\t\"type\":str(type),\n",
    "\t\t\t\"content\":content.tolist(),\n",
    "\t\t\t\"review\":output.review,\n",
    "\t\t\t\"stars\":output.stars\n",
    "\t\t}\n",
    "        return data\n",
    "    else:\n",
    "        data = {\n",
    "            \"product_id\": index,\n",
    "\t\t\t\"review\":output.review,\n",
    "\t\t\t\"stars\":output.stars\n",
    "\t\t}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74380b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ \n",
    "            \"gemma3:1b\", \n",
    "            \"deepseek-r1:1.5b\",\n",
    "            \"qwen3:1.7b\", \n",
    "            \"granite3.3:2b\", \n",
    "            \"llama3.2:1b\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8463022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kafka_publisher(topic: str, message: dict, bootstrap_servers: List[str] = [\"localhost:9092\"]):\n",
    "    \"\"\"\n",
    "    Publish a message to a Kafka topic.\n",
    "    \n",
    "    Args:\n",
    "        topic (str): The Kafka topic to publish to\n",
    "        message (dict): The message to publish (will be converted to JSON)\n",
    "        bootstrap_servers (str): Kafka broker address(es), defaults to \"localhost:9092\"\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        producer = KafkaProducer(\n",
    "            bootstrap_servers=bootstrap_servers,\n",
    "            value_serializer=lambda v: json.dumps(v).encode('utf-8'),\n",
    "            acks='all',\n",
    "            retries=3,\n",
    "            api_version=(4, 2, 0)\n",
    "        )\n",
    "        future = producer.send(topic, value=message)\n",
    "        record_metadata = future.get(timeout=10)\n",
    "        producer.close()\n",
    "        \n",
    "        # print(f\"Message published to topic '{topic}' at partition {record_metadata.partition}, offset {record_metadata.offset}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error publishing to Kafka: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kafka_consumer(topic: str, bootstrap_servers: List[str] = [\"localhost:9092\"], max_messages: int = None, callback=None):\n",
    "    \"\"\"\n",
    "    Consume messages from a Kafka topic and stop when all currently-available messages are read.\n",
    "\n",
    "    Args:\n",
    "        topic (str): The Kafka topic to consume from\n",
    "        bootstrap_servers (List[str]): Kafka broker address(es), defaults to [\"localhost:9092\"]\n",
    "        max_messages (int): Maximum number of messages to consume (None for continuous or until all current messages read)\n",
    "        callback (function): Optional callback function to process each message\n",
    "\n",
    "    Returns:\n",
    "        list or bool: List of consumed messages (if no callback provided), True if callback used and successful\n",
    "    \"\"\"\n",
    "    try:\n",
    "        consumer = KafkaConsumer(\n",
    "            topic,\n",
    "            bootstrap_servers=bootstrap_servers,\n",
    "            auto_offset_reset='earliest',\n",
    "            enable_auto_commit=True,\n",
    "            group_id='review-group',\n",
    "            value_deserializer=lambda m: json.loads(m.decode('utf-8')),\n",
    "            api_version=(4, 2, 0)\n",
    "        )\n",
    "\n",
    "        # Trigger partition assignment\n",
    "        consumer.poll(timeout_ms=1000)\n",
    "        partitions = consumer.assignment()\n",
    "        if not partitions:\n",
    "            print(\"No partitions assigned; nothing to consume.\")\n",
    "            consumer.close()\n",
    "            return []\n",
    "\n",
    "        # Determine current end offsets (the offset of the next message) for each assigned partition\n",
    "        end_offsets = consumer.end_offsets(partitions)\n",
    "\n",
    "        messages = []\n",
    "        count = 0\n",
    "\n",
    "        for message in consumer:\n",
    "            count += 1\n",
    "            data = message.value\n",
    "\n",
    "            if callback:\n",
    "                callback(data)\n",
    "            else:\n",
    "                messages.append(data)\n",
    "\n",
    "            # print(f\"Consumed message {count}: {data}\")\n",
    "\n",
    "            # Stop if we've reached the end offsets for all partitions (i.e., consumed all currently-available messages)\n",
    "            finished = True\n",
    "            for tp in partitions:\n",
    "                if consumer.position(tp) < end_offsets[tp]:\n",
    "                    finished = False\n",
    "                    break\n",
    "\n",
    "            if finished:\n",
    "                break\n",
    "\n",
    "            if max_messages and count >= max_messages:\n",
    "                break\n",
    "\n",
    "        consumer.close()\n",
    "        return messages if not callback else True\n",
    "    except Exception as e:\n",
    "        print(f\"Error consuming from Kafka: {e}\")\n",
    "        return [] if not callback else False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bfb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message published to topic 'reviews' at partition 2, offset 0\n",
      "{'product_name': 'HERMAN MILLER ELM', 'product_category': 'DRESSER', 'review_size': 'Medium', 'type': 'Positive', 'content': ['Price', 'Product appearance'], 'review': 'I was pleasantly surprised by the price of this dresser, considering its quality and appearance. The product looks great in my bedroom!', 'stars': 4}\n",
      "Message published to topic 'reviews' at partition 0, offset 0\n",
      "{'product_name': 'LG DWT-12', 'product_category': 'DISHWASHER', 'review_size': 'Small', 'type': 'Negative', 'content': ['Price', 'Functionality'], 'review': 'LG DWT-12 dishwasher arrived with a dented front panel, despite being brand new in the box. Functionality is also questionable as it struggles to clean dishes thoroughly, leaving food residue behind.', 'stars': 2}\n",
      "Message published to topic 'reviews' at partition 1, offset 0\n",
      "{'product_name': 'SAMSUNG BL-200', 'product_category': 'BLENDER', 'review_size': 'Small', 'type': 'Positive', 'content': ['Delivery', 'Functionality', 'Product appearance'], 'review': 'The SAMSUNG BL-200 blender is a solid product, offering good delivery and functionality. The appearance is clean and easy to use.', 'stars': 4}\n",
      "Message published to topic 'reviews' at partition 1, offset 1\n",
      "{'product_name': 'WHIRLPOOL WM-200', 'product_category': 'MICROWAVE', 'review_size': 'Long', 'type': 'Negative', 'content': ['Price', 'Product appearance'], 'review': \"I was really disappointed with the WHIRLPOOL WM-200 microwave. The product appearance was unattractive, with a rough and uneven surface that made it look cheap. The price was also too high for the quality offered. I expected a more modern and sleek design, but this microwave is just plain ugly. The delivery was slow, and the customer service was unhelpful. I wouldn't recommend this product to anyone. It's a 2-star review.\", 'stars': 2}\n",
      "Message published to topic 'reviews' at partition 1, offset 2\n",
      "{'product_name': 'CRATE & BARREL DESK-300', 'product_category': 'DESK', 'review_size': 'Small', 'type': 'Negative', 'content': ['Product appearance'], 'review': 'Okay, let’s be honest – this thing arrived looking *terrible*. The packaging was completely crushed, and the color isn’t what the pictures suggested. The finish on the desk itself is a matte black, which is fine, but it’s also incredibly dull and doesn’t really shine. It feels cheap and flimsy, and honestly, the design is a bit bland – it just doesn’t have any personality. It’s a small desk, so it’s supposed to be minimalist, but this feels more like a placeholder than a thoughtfully designed piece. I was really hoping for a little more visual appeal, and it’s a significant disappointment.', 'stars': 1}\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=len(models)) as executor:\n",
    "    futures = [executor.submit(generate_review, model) for model in models]\n",
    "    for future in as_completed(futures):\n",
    "        review = future.result()\n",
    "        if review:\n",
    "            kafka_publisher(topic=\"reviews\", message=review)\n",
    "            # print(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "697022b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumed message 1: {'product_name': 'LG DWT-12', 'product_category': 'DISHWASHER', 'review_size': 'Small', 'type': 'Negative', 'content': ['Price', 'Functionality'], 'review': 'LG DWT-12 dishwasher arrived with a dented front panel, despite being brand new in the box. Functionality is also questionable as it struggles to clean dishes thoroughly, leaving food residue behind.', 'stars': 2}\n",
      "Consumed message 2: {'product_name': 'SAMSUNG BL-200', 'product_category': 'BLENDER', 'review_size': 'Small', 'type': 'Positive', 'content': ['Delivery', 'Functionality', 'Product appearance'], 'review': 'The SAMSUNG BL-200 blender is a solid product, offering good delivery and functionality. The appearance is clean and easy to use.', 'stars': 4}\n",
      "Consumed message 3: {'product_name': 'WHIRLPOOL WM-200', 'product_category': 'MICROWAVE', 'review_size': 'Long', 'type': 'Negative', 'content': ['Price', 'Product appearance'], 'review': \"I was really disappointed with the WHIRLPOOL WM-200 microwave. The product appearance was unattractive, with a rough and uneven surface that made it look cheap. The price was also too high for the quality offered. I expected a more modern and sleek design, but this microwave is just plain ugly. The delivery was slow, and the customer service was unhelpful. I wouldn't recommend this product to anyone. It's a 2-star review.\", 'stars': 2}\n",
      "Consumed message 4: {'product_name': 'CRATE & BARREL DESK-300', 'product_category': 'DESK', 'review_size': 'Small', 'type': 'Negative', 'content': ['Product appearance'], 'review': 'Okay, let’s be honest – this thing arrived looking *terrible*. The packaging was completely crushed, and the color isn’t what the pictures suggested. The finish on the desk itself is a matte black, which is fine, but it’s also incredibly dull and doesn’t really shine. It feels cheap and flimsy, and honestly, the design is a bit bland – it just doesn’t have any personality. It’s a small desk, so it’s supposed to be minimalist, but this feels more like a placeholder than a thoughtfully designed piece. I was really hoping for a little more visual appeal, and it’s a significant disappointment.', 'stars': 1}\n",
      "Consumed message 5: {'product_name': 'HERMAN MILLER ELM', 'product_category': 'DRESSER', 'review_size': 'Medium', 'type': 'Positive', 'content': ['Price', 'Product appearance'], 'review': 'I was pleasantly surprised by the price of this dresser, considering its quality and appearance. The product looks great in my bedroom!', 'stars': 4}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mkafka_consumer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreviews\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_messages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mkafka_consumer\u001b[39m\u001b[34m(topic, bootstrap_servers, max_messages, callback)\u001b[39m\n\u001b[32m     25\u001b[39m messages = []\n\u001b[32m     26\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconsumer\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/rating-evaluation/.venv/lib/python3.12/site-packages/kafka/consumer/group.py:1213\u001b[39m, in \u001b[36mKafkaConsumer.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1211\u001b[39m     \u001b[38;5;28mself\u001b[39m._iterator = \u001b[38;5;28mself\u001b[39m._message_generator_v2()\n\u001b[32m   1212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   1215\u001b[39m     \u001b[38;5;28mself\u001b[39m._iterator = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/rating-evaluation/.venv/lib/python3.12/site-packages/kafka/consumer/group.py:1185\u001b[39m, in \u001b[36mKafkaConsumer._message_generator_v2\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_message_generator_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1184\u001b[39m     timeout_ms = \u001b[32m1000\u001b[39m * \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mself\u001b[39m._consumer_timeout - time.time())\n\u001b[32m-> \u001b[39m\u001b[32m1185\u001b[39m     record_map = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1186\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m tp, records \u001b[38;5;129;01min\u001b[39;00m six.iteritems(record_map):\n\u001b[32m   1187\u001b[39m         \u001b[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[32m   1188\u001b[39m         \u001b[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[32m   1189\u001b[39m         \u001b[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[32m   1190\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n\u001b[32m   1191\u001b[39m             \u001b[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[32m   1192\u001b[39m             \u001b[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[32m   1193\u001b[39m             \u001b[38;5;66;03m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[32m   1194\u001b[39m             \u001b[38;5;66;03m# via self._iterator = None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/rating-evaluation/.venv/lib/python3.12/site-packages/kafka/consumer/group.py:708\u001b[39m, in \u001b[36mKafkaConsumer.poll\u001b[39m\u001b[34m(self, timeout_ms, max_records, update_offsets)\u001b[39m\n\u001b[32m    706\u001b[39m timer = Timer(timeout_ms)\n\u001b[32m    707\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._closed:\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m     records = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[32m    710\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/rating-evaluation/.venv/lib/python3.12/site-packages/kafka/consumer/group.py:757\u001b[39m, in \u001b[36mKafkaConsumer._poll_once\u001b[39m\u001b[34m(self, timer, max_records, update_offsets)\u001b[39m\n\u001b[32m    754\u001b[39m     log.debug(\u001b[33m'\u001b[39m\u001b[33mpoll: do not have all fetch positions...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    755\u001b[39m     poll_timeout_ms = \u001b[38;5;28mmin\u001b[39m(poll_timeout_ms, \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mretry_backoff_ms\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoll_timeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[32m    759\u001b[39m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._coordinator.need_rejoin():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/rating-evaluation/.venv/lib/python3.12/site-packages/kafka/client_async.py:685\u001b[39m, in \u001b[36mKafkaClient.poll\u001b[39m\u001b[34m(self, timeout_ms, future)\u001b[39m\n\u001b[32m    678\u001b[39m         timeout = \u001b[38;5;28mmin\u001b[39m(\n\u001b[32m    679\u001b[39m             user_timeout_ms,\n\u001b[32m    680\u001b[39m             metadata_timeout_ms,\n\u001b[32m    681\u001b[39m             idle_connection_timeout_ms,\n\u001b[32m    682\u001b[39m             request_timeout_ms)\n\u001b[32m    683\u001b[39m         timeout = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[32m    688\u001b[39m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[32m    689\u001b[39m responses.extend(\u001b[38;5;28mself\u001b[39m._fire_pending_completed_requests())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/rating-evaluation/.venv/lib/python3.12/site-packages/kafka/client_async.py:728\u001b[39m, in \u001b[36mKafkaClient._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    725\u001b[39m \u001b[38;5;28mself\u001b[39m._register_send_sockets()\n\u001b[32m    727\u001b[39m start_select = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ready = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    729\u001b[39m end_select = time.time()\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sensors:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/selectors.py:468\u001b[39m, in \u001b[36mEpollSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    466\u001b[39m ready = []\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "kafka_consumer(topic=\"reviews\", max_messages=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rating-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
