{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b73790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.agents import create_agent\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "# from langchain.agents.structured_output import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78d202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load(\"models/model.pkl\")\n",
    "vectorizer = joblib.load(\"models/vectorizer.pkl\")\n",
    "\n",
    "def predict(text):\n",
    "    vec = vectorizer.transform([text])\n",
    "    return model.predict(vec)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25161de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review(BaseModel):\n",
    "    review: str = Field(\n",
    "        description=\"Text of the review\"\n",
    "    )\n",
    "    stars: int = Field(\n",
    "        description=\"The quantity of stars on the rating\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9558ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(\n",
    "    model=\"gemma3:12b\",\n",
    "    temperature=0.5,\n",
    "    validate_model_on_init=True,\n",
    "    seed=1234,\n",
    "    num_ctx=65536,\n",
    "    reasoning=False\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Review)\n",
    "\n",
    "str_prompt = \"\"\"\n",
    "You are a product review generator.\n",
    "\n",
    "Your task is to create a customer-style product review based on the information provided below.\n",
    "\n",
    "Product name: {product_name}\n",
    "Category: {product_category}\n",
    "Review size: {review_size}\n",
    "Review type: {type}\n",
    "Aspect being reviewed: {content}\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "1. The review must sound natural, like a real customer experience.\n",
    "2. The tone must strictly follow the review type:\n",
    "   - If the type is positive, the overall sentiment must be positive.\n",
    "   - If the type is negative, the overall sentiment must be negative.\n",
    "3. Reviews may be controversial:\n",
    "   - The text may include mixed opinions.\n",
    "   - The star rating may be slightly unexpected.\n",
    "   - Even so, the final sentiment must always respect the defined review type.\n",
    "4. The review must focus mainly on the specified aspect:\n",
    "   - Delivery\n",
    "   - Product appearance\n",
    "   - Functionality\n",
    "   - Price\n",
    "5. The product name may be mentioned in the review, but prefer to not mention.\n",
    "6. Follow the review size rules:\n",
    "   - Small: exactly one sentence.\n",
    "   - Medium: at least two sentences.\n",
    "   - Long: one paragraph with at least 5 lines.\n",
    "7. Assign a star rating from 1 to 5 that matches the overall sentiment:\n",
    "   - Negative reviews â†’ 1 or 2 stars (controversial cases may slightly vary)\n",
    "   - Neutral or mixed but positive â†’ 3 stars\n",
    "   - Clearly positive â†’ 4 or 5 stars\n",
    "Output format (strictly follow this format):\n",
    "\n",
    "Review:\n",
    "<generated review text>\n",
    "\n",
    "Stars:\n",
    "<number from 1 to 5>\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "      ([\"system\", str_prompt]),\n",
    "      partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f8179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/products.csv')\n",
    "products = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c84cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_review_size = ['Small', 'Medium', 'Long']\n",
    "list_type = ['Positive', 'Negative']\n",
    "list_content = [\n",
    "    'Delivery',\n",
    "    'Product appearance',\n",
    "    'Functionality',\n",
    "    'Price',\n",
    "]\n",
    "list_index_produtcs = [i for i in range(1, 100, 1)]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6edce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "qt_reviews = 1000\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e365eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_reviews = []\n",
    "while i <= qt_reviews:\n",
    "\n",
    "    review_size =  np.random.choice(list_review_size, size=None, replace=True, p=None)\n",
    "    type = np.random.choice(list_type, size=None, replace=True, p=None)\n",
    "    content = np.random.choice(list_content, size=np.random.randint(1, len(list_content)), replace=False, p=None)\n",
    "    index = np.random.choice(list_index_produtcs, size=None, replace=True, p=None)\n",
    "    product = products[index]\n",
    "\n",
    "    try:\n",
    "        output = chain.invoke(\n",
    "            {\n",
    "                \"product_name\":product[0],\n",
    "                \"product_category\":product[1],\n",
    "                \"review_size\":review_size,\n",
    "                \"type\":type,\n",
    "                \"content\":content\n",
    "            }\n",
    "            )\n",
    "        \n",
    "        data = {\n",
    "            \"product_name\":product[0],\n",
    "            \"product_category\":product[1],\n",
    "            \"review_size\":review_size,\n",
    "            \"type\":type,\n",
    "            \"content\":content,\n",
    "            \"review\":output.review,\n",
    "            \"stars\":output.stars\n",
    "        }\n",
    "        list_of_reviews.append(data)\n",
    "        if i%100 == 0 and i != 0:\n",
    "            pd.DataFrame(list_of_reviews).to_csv(\"reviews.csv\", index=False)\n",
    "\n",
    "        i += 1\n",
    "    except Exception as e:\n",
    "        pd.DataFrame(list_of_reviews).to_csv(\"reviews.csv\", index=False)\n",
    "        raise(e)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4d0a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas: 101\n",
      "\n",
      "DistribuiÃ§Ã£o de sentimentos:\n",
      "type\n",
      "Positive    52\n",
      "Negative    49\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/reviews_1.csv\")\n",
    "\n",
    "print(\"Total de linhas:\", len(df))\n",
    "print(\"\\nDistribuiÃ§Ã£o de sentimentos:\")\n",
    "print(df[\"type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc12e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 101 entries, 0 to 100\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   product_name      101 non-null    str  \n",
      " 1   product_category  101 non-null    str  \n",
      " 2   review_size       101 non-null    str  \n",
      " 3   type              101 non-null    str  \n",
      " 4   content           101 non-null    str  \n",
      " 5   review            101 non-null    str  \n",
      " 6   stars             101 non-null    int64\n",
      "dtypes: int64(1), str(6)\n",
      "memory usage: 5.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "type\n",
       "Positive    52\n",
       "Negative    49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()\n",
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "929180f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run gaudy-fly-884 at: http://127.0.0.1:5000/#/experiments/2/runs/d6cb51ebe35a40a0838c4e2b07157f72\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m mlflow.set_experiment(\u001b[33m\"\u001b[39m\u001b[33mSentiment-Analysis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run():\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     model.fit(\u001b[43mX_train_vec\u001b[49m, y_train)\n\u001b[32m     10\u001b[39m     y_pred = model.predict(X_test_vec)\n\u001b[32m     11\u001b[39m     f1 = f1_score(y_test, y_pred)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_vec' is not defined"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Sentiment-Analysis\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"logistic_regression\")\n",
    "    mlflow.log_param(\"vectorizer\", \"tfidf\")\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"SentimentModel\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rating-evaluation (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
