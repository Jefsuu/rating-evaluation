{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d40ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.agents import create_agent\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "# from langchain.agents.structured_output import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = None\n",
    "class Review(BaseModel):\n",
    "    review: str = Field(\n",
    "        description=\"Text of the review\"\n",
    "    )\n",
    "    stars: int = Field(\n",
    "        description=\"The quantity of stars on the rating\"\n",
    "    )\n",
    "\n",
    "llm = OllamaLLM(\n",
    "    model=\"gemma3:12b\",\n",
    "    temperature=0.8,\n",
    "    validate_model_on_init=True,\n",
    "    seed=1234,\n",
    "    num_ctx=65536,\n",
    "    reasoning=False\n",
    "    \n",
    ")\n",
    "parser = PydanticOutputParser(pydantic_object=Review)\n",
    "\n",
    "str_prompt = \"\"\"\n",
    "You are a product review generator.\n",
    "\n",
    "Your task is to create a customer-style product review based on the information provided below.\n",
    "\n",
    "Product name: {product_name}\n",
    "Category: {product_category}\n",
    "Review size: {review_size}\n",
    "Review type: {type}\n",
    "Aspect being reviewed: {content}\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "1. The review must sound natural, like a real customer experience.\n",
    "2. The tone must strictly follow the review type:\n",
    "   - If the type is positive, the overall sentiment must be positive.\n",
    "   - If the type is negative, the overall sentiment must be negative.\n",
    "3. Reviews may be controversial:\n",
    "   - The text may include mixed opinions.\n",
    "   - The star rating may be slightly unexpected.\n",
    "   - Even so, the final sentiment must always respect the defined review type.\n",
    "4. The review must focus mainly on the specified aspect:\n",
    "   - Delivery\n",
    "   - Product appearance\n",
    "   - Functionality\n",
    "   - Price\n",
    "5. The product name may be mentioned in the review, but prefer to not mention.\n",
    "6. Follow the review size rules:\n",
    "   - Small: exactly one sentence.\n",
    "   - Medium: at least two sentences.\n",
    "   - Long: one paragraph with at least 5 lines.\n",
    "7. Assign a star rating from 1 to 5 that matches the overall sentiment:\n",
    "   - Negative reviews → 1 or 2 stars (controversial cases may slightly vary)\n",
    "   - Neutral or mixed but positive → 3 stars\n",
    "   - Clearly positive → 4 or 5 stars\n",
    "Output format (strictly follow this format):\n",
    "\n",
    "Review:\n",
    "<generated review text>\n",
    "\n",
    "Stars:\n",
    "<number from 1 to 5>\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "      ([\"system\", str_prompt]),\n",
    "      partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "      )\n",
    "df = pd.read_csv('data/produtcs.csv')\n",
    "products = df.values\n",
    "list_review_size = ['Small', 'Medium', 'Long']\n",
    "list_type = ['Positive', 'Negative']\n",
    "list_content = [\n",
    "    'Delivery',\n",
    "    'Product appearance',\n",
    "    'Functionality',\n",
    "    'Price',\n",
    "]\n",
    "list_index_produtcs = [i for i in range(1, 100, 1)]\n",
    " \n",
    "# chain = prompt | llm | parser\n",
    "# qt_reviews = 5\n",
    "# i = 0\n",
    "# list_of_reviews = []\n",
    "# while i <= qt_reviews:\n",
    "\n",
    "#     review_size =  np.random.choice(list_review_size, size=None, replace=True, p=None)\n",
    "#     type = np.random.choice(list_type, size=None, replace=True, p=None)\n",
    "#     content = np.random.choice(list_content, size=np.random.randint(1, len(list_content)), replace=False, p=None)\n",
    "#     index = np.random.choice(list_index_produtcs, size=None, replace=True, p=None)\n",
    "#     product = products[index]\n",
    "\n",
    "#     try:\n",
    "#         output = chain.invoke(\n",
    "#             {\n",
    "#                 \"product_name\":product[0],\n",
    "#                 \"product_category\":product[1],\n",
    "#                 \"review_size\":review_size,\n",
    "#                 \"type\":type,\n",
    "#                 \"content\":content\n",
    "#             }\n",
    "#             )\n",
    "        \n",
    "#         data = {\n",
    "#             \"product_name\":product[0],\n",
    "#             \"product_category\":product[1],\n",
    "#             \"review_size\":review_size,\n",
    "#             \"type\":type,\n",
    "#             \"content\":content,\n",
    "#             \"review\":output.review,\n",
    "#             \"stars\":output.stars\n",
    "#         }\n",
    "#         list_of_reviews.append(data)\n",
    "#     except Exception:\n",
    "#         raise Exception\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "from langchain.tools import tool\n",
    "\n",
    "predictor = TabularPredictor.load(\"AutogluonModels/ag-20260131_224624\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "681bdf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def review_classifier(review: Review):\n",
    "\n",
    "\t\"\"\"Evalute if the review is postive or negative\"\"\"\n",
    "\ttext = review.review\n",
    "\tdata = pd.DataFrame([{\"review\": text}])\n",
    "\tpred = predictor.predict(data)\n",
    "\tproba = predictor.predict_proba(data)\n",
    "\treturn {\n",
    "\t\"type\": pred,\n",
    "\t\"proba\": float(proba.max())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "112bb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "import pandas as pd\n",
    "from typing import Type\n",
    "\n",
    "class ReviewClassifierInput(BaseModel):\n",
    "    review: Review\n",
    "\n",
    "class ReviewClassifierTool(BaseTool):\n",
    "    name: str = Field(\"review_classifier\")\n",
    "    description: str = Field(\"Evaluate if a review is positive or negative\")\n",
    "    args_schema: Type[BaseModel] = ReviewClassifierInput\n",
    "\n",
    "    def _run(self, review: Review):\n",
    "\n",
    "        data = pd.DataFrame([{\"review\": review.review}])\n",
    "        pred = predictor.predict(data)\n",
    "        proba = predictor.predict_proba(data)\n",
    "\n",
    "        return {\n",
    "            \"type\": pred.iloc[0],\n",
    "            \"proba\": proba.iloc[0].max()\n",
    "        }\n",
    "review_classifier = ReviewClassifierTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15043da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "wrap_review_for_tool = RunnableLambda(\n",
    "    lambda review: {\"review\": review}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f7878e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser | wrap_review_for_tool | review_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1aa706b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Negative', 'proba': np.float64(0.9999973177909851)}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "                \"product_name\":\"GE JLM 50\",\n",
    "                \"product_category\":\"STOVE\",\n",
    "                \"review_size\":\"Long\",\n",
    "                \"type\":\"Negative\",\n",
    "                \"content\":['Delivery' 'Price' 'Functionality']\n",
    "            }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bcbd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rating-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
