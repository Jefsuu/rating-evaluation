{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657afc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jef/repos/rating-evaluation/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularPredictor, TabularPredictor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f7bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_csv_with_prefix(folder_path: str, prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads all CSV files in *folder_path* that start with *prefix*,\n",
    "    concatenates them into a single DataFrame, and returns it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Path to the directory containing the CSV files.\n",
    "    prefix : str\n",
    "        Prefix that the target CSV filenames must start with.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Concatenated DataFrame containing all rows from the matched files.\n",
    "    \"\"\"\n",
    "    # Build glob pattern: e.g. \"data/reviews_*.csv\"\n",
    "    pattern = os.path.join(folder_path, f\"{prefix}*.csv\")\n",
    "    csv_files = sorted(glob.glob(pattern))\n",
    "\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found with prefix '{prefix}' in {folder_path}\")\n",
    "\n",
    "    # Read each file into a DataFrame\n",
    "    df_list = [pd.read_csv(f) for f in csv_files]\n",
    "\n",
    "    # Concatenate all DataFrames, resetting the index\n",
    "    return pd.concat(df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb19e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>review_size</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>review</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung W-3000</td>\n",
       "      <td>WASHING_MACHINE</td>\n",
       "      <td>Long</td>\n",
       "      <td>Positive</td>\n",
       "      <td>['Functionality']</td>\n",
       "      <td>I recently upgraded to the Samsung W-3000 and ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Panasonic W-7000</td>\n",
       "      <td>WASHING_MACHINE</td>\n",
       "      <td>Small</td>\n",
       "      <td>Negative</td>\n",
       "      <td>['Delivery' 'Delivery' 'Functionality']</td>\n",
       "      <td>I was disappointed with the Panasonic W-7000 b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Electrolux L3-400</td>\n",
       "      <td>REFRIGERATOR</td>\n",
       "      <td>Long</td>\n",
       "      <td>Positive</td>\n",
       "      <td>['Price' 'Product appearance']</td>\n",
       "      <td>I was pleasantly surprised by the Electrolux L...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Panasonic Q2-300</td>\n",
       "      <td>REFRIGERATOR</td>\n",
       "      <td>Small</td>\n",
       "      <td>Positive</td>\n",
       "      <td>['Functionality']</td>\n",
       "      <td>The Panasonic Q2-300 keeps my groceries fresh ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pottery Barn S-2100</td>\n",
       "      <td>SOFA</td>\n",
       "      <td>Long</td>\n",
       "      <td>Negative</td>\n",
       "      <td>['Price' 'Functionality']</td>\n",
       "      <td>I was excited to add the Pottery Barn S-2100 t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product_name product_category review_size      type  \\\n",
       "0       Samsung W-3000  WASHING_MACHINE        Long  Positive   \n",
       "1     Panasonic W-7000  WASHING_MACHINE       Small  Negative   \n",
       "2    Electrolux L3-400     REFRIGERATOR        Long  Positive   \n",
       "3     Panasonic Q2-300     REFRIGERATOR       Small  Positive   \n",
       "4  Pottery Barn S-2100             SOFA        Long  Negative   \n",
       "\n",
       "                                   content  \\\n",
       "0                        ['Functionality']   \n",
       "1  ['Delivery' 'Delivery' 'Functionality']   \n",
       "2           ['Price' 'Product appearance']   \n",
       "3                        ['Functionality']   \n",
       "4                ['Price' 'Functionality']   \n",
       "\n",
       "                                              review  stars  \n",
       "0  I recently upgraded to the Samsung W-3000 and ...      5  \n",
       "1  I was disappointed with the Panasonic W-7000 b...      1  \n",
       "2  I was pleasantly surprised by the Electrolux L...      5  \n",
       "3  The Panasonic Q2-300 keeps my groceries fresh ...      5  \n",
       "4  I was excited to add the Pottery Barn S-2100 t...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = concat_csv_with_prefix(\"data\", \"review\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652a453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['review', 'type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b87e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb77d316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20260131_224624\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.12.3\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025\n",
      "CPU Count:          12\n",
      "Pytorch Version:    2.9.1+cu128\n",
      "CUDA Version:       12.8\n",
      "GPU Memory:         GPU 0: 15.92/15.92 GB\n",
      "Total GPU Memory:   Free: 15.92 GB, Allocated: 0.00 GB, Total: 15.92 GB\n",
      "GPU Count:          1\n",
      "Memory Avail:       17.61 GB / 23.47 GB (75.0%)\n",
      "Disk Space Avail:   839.08 GB / 1006.85 GB (83.3%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme'  : New in v1.5: The state-of-the-art for tabular data. Massively better than 'best' on datasets <100000 samples by using new Tabular Foundation Models (TFMs) meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, TabDPT, and TabM. Requires a GPU and `pip install autogluon.tabular[tabarena]` to install TabPFN, TabICL, and TabDPT.\n",
      "\tpresets='best'     : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='best_v150': New in v1.5: Better quality than 'best' and 5x+ faster to train. Give it a try!\n",
      "\tpresets='high'     : Strong accuracy with fast inference speed.\n",
      "\tpresets='high_v150': New in v1.5: Better quality than 'high' and 5x+ faster to train. Give it a try!\n",
      "\tpresets='good'     : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'   : Fast training time, ideal for initial prototyping.\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/jef/repos/rating-evaluation/AutogluonModels/ag-20260131_224624\"\n",
      "Train Data Rows:    1799\n",
      "Train Data Columns: 1\n",
      "Label Column:       type\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['Positive', 'Negative']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Positive, class 0 = Negative\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Positive) vs negative (Negative) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18022.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.30 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['review']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 1203\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', ['text']) : 1 | ['review']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :    1 | ['review']\n",
      "\t\t('int', ['binned', 'text_special']) :   20 | ['review.char_count', 'review.word_count', 'review.capital_ratio', 'review.lower_ratio', 'review.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 1159 | ['__nlp__.about', '__nlp__.about the', '__nlp__.absolute', '__nlp__.absolute nightmare', '__nlp__.absolutely', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t1 features in original data used to generate 1180 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.83s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1439, Val Rows: 360\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ...\n",
      "\tFitting with cpus=6, gpus=0, mem=0.2/17.5 GB\n",
      "\t0.9944\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tFitting with cpus=6, gpus=0, mem=0.2/17.4 GB\n",
      "\t0.9972\t = Validation score   (accuracy)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t0.9917\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t0.9944\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tFitting with cpus=6, gpus=0, mem=1.4/17.0 GB\n",
      "\t0.9972\t = Validation score   (accuracy)\n",
      "\t1.82s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t0.9944\t = Validation score   (accuracy)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t0.9972\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tFitting with cpus=6, gpus=0, mem=0.0/16.5 GB\n",
      "\t0.7528\t = Validation score   (accuracy)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tFitting with cpus=6, gpus=0\n",
      "\t0.9861\t = Validation score   (accuracy)\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting with cpus=6, gpus=0, mem=0.0/16.2 GB\n",
      "\t0.7639\t = Validation score   (accuracy)\n",
      "\t5.73s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tFitting with cpus=6, gpus=0, mem=0.9/15.7 GB\n",
      "\t0.9778\t = Validation score   (accuracy)\n",
      "\t1.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=12, gpus=0, mem=0.0/15.5 GB\n",
      "\tEnsemble Weights: {'LightGBM': 1.0}\n",
      "\t0.9972\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.28s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 69753.3 rows/s (360 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (360 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/jef/repos/rating-evaluation/AutogluonModels/ag-20260131_224624\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=\"type\").fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "783c0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = predictor.predict(df_test.drop(columns=[\"type\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e33c62d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1707    Negative\n",
       "2189    Positive\n",
       "789     Negative\n",
       "140     Positive\n",
       "775     Positive\n",
       "Name: type, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7bf944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1707    Negative\n",
       "2189    Positive\n",
       "789     Negative\n",
       "140     Positive\n",
       "775     Positive\n",
       "Name: type, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c723a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.991111</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.121642</td>\n",
       "      <td>0.111867</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.121642</td>\n",
       "      <td>0.111867</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.115358</td>\n",
       "      <td>0.111237</td>\n",
       "      <td>0.955261</td>\n",
       "      <td>0.115358</td>\n",
       "      <td>0.111237</td>\n",
       "      <td>0.955261</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>1.822124</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>1.822124</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.118620</td>\n",
       "      <td>0.109818</td>\n",
       "      <td>0.800567</td>\n",
       "      <td>0.118620</td>\n",
       "      <td>0.109818</td>\n",
       "      <td>0.800567</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.110705</td>\n",
       "      <td>0.730436</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.110705</td>\n",
       "      <td>0.730436</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.539779</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.539779</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.569671</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.029892</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.701447</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.701447</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.971111</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.013737</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>1.165107</td>\n",
       "      <td>0.013737</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>1.165107</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.964444</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>1.131653</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>1.131653</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.735556</td>\n",
       "      <td>0.752778</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.004830</td>\n",
       "      <td>0.418406</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.004830</td>\n",
       "      <td>0.418406</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.009439</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>5.734832</td>\n",
       "      <td>0.009439</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>5.734832</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0        ExtraTreesEntr    0.991111   0.997222    accuracy        0.121642   \n",
       "1        ExtraTreesGini    0.988889   0.994444    accuracy        0.115358   \n",
       "2              CatBoost    0.986667   0.997222    accuracy        0.019312   \n",
       "3      RandomForestGini    0.986667   0.991667    accuracy        0.118620   \n",
       "4      RandomForestEntr    0.986667   0.994444    accuracy        0.121053   \n",
       "5              LightGBM    0.982222   0.997222    accuracy        0.006859   \n",
       "6   WeightedEnsemble_L2    0.982222   0.997222    accuracy        0.008492   \n",
       "7            LightGBMXT    0.982222   0.994444    accuracy        0.010037   \n",
       "8               XGBoost    0.971111   0.986111    accuracy        0.013737   \n",
       "9         LightGBMLarge    0.964444   0.977778    accuracy        0.013343   \n",
       "10      NeuralNetFastAI    0.735556   0.752778    accuracy        0.012054   \n",
       "11       NeuralNetTorch    0.711111   0.763889    accuracy        0.009439   \n",
       "\n",
       "    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.111867  0.747021                 0.121642                0.111867   \n",
       "1        0.111237  0.955261                 0.115358                0.111237   \n",
       "2        0.016137  1.822124                 0.019312                0.016137   \n",
       "3        0.109818  0.800567                 0.118620                0.109818   \n",
       "4        0.110705  0.730436                 0.121053                0.110705   \n",
       "5        0.004838  0.539779                 0.006859                0.004838   \n",
       "6        0.005161  0.569671                 0.001633                0.000323   \n",
       "7        0.004478  0.701447                 0.010037                0.004478   \n",
       "8        0.004120  1.165107                 0.013737                0.004120   \n",
       "9        0.004316  1.131653                 0.013343                0.004316   \n",
       "10       0.004830  0.418406                 0.012054                0.004830   \n",
       "11       0.008541  5.734832                 0.009439                0.008541   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.747021            1       True          7  \n",
       "1            0.955261            1       True          6  \n",
       "2            1.822124            1       True          5  \n",
       "3            0.800567            1       True          3  \n",
       "4            0.730436            1       True          4  \n",
       "5            0.539779            1       True          2  \n",
       "6            0.029892            2       True         12  \n",
       "7            0.701447            1       True          1  \n",
       "8            1.165107            1       True          9  \n",
       "9            1.131653            1       True         11  \n",
       "10           0.418406            1       True          8  \n",
       "11           5.734832            1       True         10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e4b2fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('category', ['text_as_category'])  :    1 | ['review']\n",
      "('int', ['binned', 'text_special']) :   20 | ['review.char_count', 'review.word_count', 'review.capital_ratio', 'review.lower_ratio', 'review.digit_ratio', ...]\n",
      "('int', ['text_ngram'])             : 1159 | ['__nlp__.about', '__nlp__.about the', '__nlp__.absolute', '__nlp__.absolute nightmare', '__nlp__.absolutely', ...]\n"
     ]
    }
   ],
   "source": [
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c59d40cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 1 features using 450 rows with 5 shuffle sets...\n",
      "\t0.52s\t= Expected runtime (0.1s per shuffle set)\n",
      "\t0.33s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>1.500132e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.498586</td>\n",
       "      <td>0.461414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        importance    stddev       p_value  n  p99_high   p99_low\n",
       "review        0.48  0.009027  1.500132e-08  5  0.498586  0.461414"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd3acd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9822222222222222,\n",
       " 'balanced_accuracy': np.float64(0.9822783309625416),\n",
       " 'mcc': 0.9644804455240376,\n",
       " 'roc_auc': np.float64(0.9986170380907222),\n",
       " 'f1': 0.9820627802690582,\n",
       " 'precision': 0.9776785714285714,\n",
       " 'recall': 0.9864864864864865}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ecdf4",
   "metadata": {},
   "source": [
    "# Path of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b3aa83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jef/repos/rating-evaluation/AutogluonModels/ag-20260131_224624/predictor.pkl'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(predictor.path, predictor.predictor_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rating-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
