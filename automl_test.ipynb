{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "657afc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularPredictor, TabularPredictor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31f7bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_csv_with_prefix(folder_path: str, prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads all CSV files in *folder_path* that start with *prefix*,\n",
    "    concatenates them into a single DataFrame, and returns it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Path to the directory containing the CSV files.\n",
    "    prefix : str\n",
    "        Prefix that the target CSV filenames must start with.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Concatenated DataFrame containing all rows from the matched files.\n",
    "    \"\"\"\n",
    "    # Build glob pattern: e.g. \"data/reviews_*.csv\"\n",
    "    pattern = os.path.join(folder_path, f\"{prefix}*.csv\")\n",
    "    csv_files = sorted(glob.glob(pattern))\n",
    "\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found with prefix '{prefix}' in {folder_path}\")\n",
    "\n",
    "    # Read each file into a DataFrame\n",
    "    df_list = [pd.read_csv(f) for f in csv_files]\n",
    "\n",
    "    # Concatenate all DataFrames, resetting the index\n",
    "    return pd.concat(df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fb19e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>review_size</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>review</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung W-3000</td>\n",
       "      <td>WASHING_MACHINE</td>\n",
       "      <td>Long</td>\n",
       "      <td>Positive</td>\n",
       "      <td>['Functionality']</td>\n",
       "      <td>I recently upgraded to the Samsung W-3000 and I have to say, its functionality is top‑notch.\\nThe load‑sensing technology automatically adjusts water usage, which has saved me a surprising amount on my monthly bills.\\nI love how the machine offers a wide range of wash cycles, from quick 15‑minute cleans to deep‑tissue steam options, so I can tackle any fabric type with confidence.\\nThe quiet motor is almost whisper‑quiet, even during the spin cycle, which is a huge plus for our open‑plan living space.\\nFinally, the intuitive touchscreen interface makes it a breeze to set up custom wash pro...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Panasonic W-7000</td>\n",
       "      <td>WASHING_MACHINE</td>\n",
       "      <td>Small</td>\n",
       "      <td>Negative</td>\n",
       "      <td>['Delivery' 'Delivery' 'Functionality']</td>\n",
       "      <td>I was disappointed with the Panasonic W-7000 because the delivery was delayed and the machine stopped working after just a week.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Electrolux L3-400</td>\n",
       "      <td>REFRIGERATOR</td>\n",
       "      <td>Long</td>\n",
       "      <td>Positive</td>\n",
       "      <td>['Price' 'Product appearance']</td>\n",
       "      <td>I was pleasantly surprised by the Electrolux L3‑400’s sleek design – the stainless steel finish looks like it belongs in a modern kitchen, and the minimalist door handles give it a very premium feel.  The price point is surprisingly reasonable for a unit of this size and quality; I felt like I was getting a lot of value for my money.  Inside, the spacious compartments and adjustable shelves make it easy to organize everything from groceries to large containers.  The quiet operation is a bonus, especially when the fridge is in the living area.  Overall, I’m thrilled with both the look and t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Panasonic Q2-300</td>\n",
       "      <td>REFRIGERATOR</td>\n",
       "      <td>Small</td>\n",
       "      <td>Positive</td>\n",
       "      <td>['Functionality']</td>\n",
       "      <td>The Panasonic Q2-300 keeps my groceries fresh and the temperature control is spot‑on, making it a standout in terms of functionality.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pottery Barn S-2100</td>\n",
       "      <td>SOFA</td>\n",
       "      <td>Long</td>\n",
       "      <td>Negative</td>\n",
       "      <td>['Price' 'Functionality']</td>\n",
       "      <td>I was excited to add the Pottery Barn S-2100 to my living room, but it turned out to be a major disappointment.\\nThe price tag alone felt like a stretch for what the sofa offers—it's far more expensive than comparable models from other brands.\\nFunctionally, the cushions sag quickly, and the back support is almost nonexistent, making it uncomfortable after a short sit.\\nThe fabric also shows stains after just a few weeks of use, which is unacceptable for a piece marketed as premium.\\nOverall, I regret the purchase and would not recommend this sofa to anyone on a budget or looking for durab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product_name product_category review_size      type  \\\n",
       "0       Samsung W-3000  WASHING_MACHINE        Long  Positive   \n",
       "1     Panasonic W-7000  WASHING_MACHINE       Small  Negative   \n",
       "2    Electrolux L3-400     REFRIGERATOR        Long  Positive   \n",
       "3     Panasonic Q2-300     REFRIGERATOR       Small  Positive   \n",
       "4  Pottery Barn S-2100             SOFA        Long  Negative   \n",
       "\n",
       "                                   content  \\\n",
       "0                        ['Functionality']   \n",
       "1  ['Delivery' 'Delivery' 'Functionality']   \n",
       "2           ['Price' 'Product appearance']   \n",
       "3                        ['Functionality']   \n",
       "4                ['Price' 'Functionality']   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    review  \\\n",
       "0  I recently upgraded to the Samsung W-3000 and I have to say, its functionality is top‑notch.\\nThe load‑sensing technology automatically adjusts water usage, which has saved me a surprising amount on my monthly bills.\\nI love how the machine offers a wide range of wash cycles, from quick 15‑minute cleans to deep‑tissue steam options, so I can tackle any fabric type with confidence.\\nThe quiet motor is almost whisper‑quiet, even during the spin cycle, which is a huge plus for our open‑plan living space.\\nFinally, the intuitive touchscreen interface makes it a breeze to set up custom wash pro...   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         I was disappointed with the Panasonic W-7000 because the delivery was delayed and the machine stopped working after just a week.   \n",
       "2  I was pleasantly surprised by the Electrolux L3‑400’s sleek design – the stainless steel finish looks like it belongs in a modern kitchen, and the minimalist door handles give it a very premium feel.  The price point is surprisingly reasonable for a unit of this size and quality; I felt like I was getting a lot of value for my money.  Inside, the spacious compartments and adjustable shelves make it easy to organize everything from groceries to large containers.  The quiet operation is a bonus, especially when the fridge is in the living area.  Overall, I’m thrilled with both the look and t...   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    The Panasonic Q2-300 keeps my groceries fresh and the temperature control is spot‑on, making it a standout in terms of functionality.   \n",
       "4  I was excited to add the Pottery Barn S-2100 to my living room, but it turned out to be a major disappointment.\\nThe price tag alone felt like a stretch for what the sofa offers—it's far more expensive than comparable models from other brands.\\nFunctionally, the cushions sag quickly, and the back support is almost nonexistent, making it uncomfortable after a short sit.\\nThe fabric also shows stains after just a few weeks of use, which is unacceptable for a piece marketed as premium.\\nOverall, I regret the purchase and would not recommend this sofa to anyone on a budget or looking for durab...   \n",
       "\n",
       "   stars  \n",
       "0      5  \n",
       "1      1  \n",
       "2      5  \n",
       "3      5  \n",
       "4      1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = concat_csv_with_prefix(\"data\", \"review\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b87e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb77d316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20260131_005049\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.12.3\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025\n",
      "CPU Count:          12\n",
      "Pytorch Version:    2.9.1+cu128\n",
      "CUDA Version:       12.8\n",
      "GPU Memory:         GPU 0: 15.92/15.92 GB\n",
      "Total GPU Memory:   Free: 15.92 GB, Allocated: 0.00 GB, Total: 15.92 GB\n",
      "GPU Count:          1\n",
      "Memory Avail:       17.70 GB / 23.47 GB (75.4%)\n",
      "Disk Space Avail:   839.33 GB / 1006.85 GB (83.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme'  : New in v1.5: The state-of-the-art for tabular data. Massively better than 'best' on datasets <100000 samples by using new Tabular Foundation Models (TFMs) meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, TabDPT, and TabM. Requires a GPU and `pip install autogluon.tabular[tabarena]` to install TabPFN, TabICL, and TabDPT.\n",
      "\tpresets='best'     : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='best_v150': New in v1.5: Better quality than 'best' and 5x+ faster to train. Give it a try!\n",
      "\tpresets='high'     : Strong accuracy with fast inference speed.\n",
      "\tpresets='high_v150': New in v1.5: Better quality than 'high' and 5x+ faster to train. Give it a try!\n",
      "\tpresets='good'     : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'   : Fast training time, ideal for initial prototyping.\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/jef/repos/rating-evaluation/AutogluonModels/ag-20260131_005049\"\n",
      "Train Data Rows:    1799\n",
      "Train Data Columns: 6\n",
      "Label Column:       type\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['Positive', 'Negative']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Positive, class 0 = Negative\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Positive) vs negative (Negative) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18130.65 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.76 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['content', 'review']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 1255\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['stars']\n",
      "\t\t('object', [])       : 3 | ['product_name', 'product_category', 'review_size']\n",
      "\t\t('object', ['text']) : 2 | ['content', 'review']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    3 | ['product_name', 'product_category', 'review_size']\n",
      "\t\t('category', ['text_as_category'])  :    2 | ['content', 'review']\n",
      "\t\t('int', [])                         :    1 | ['stars']\n",
      "\t\t('int', ['binned', 'text_special']) :   26 | ['content.char_count', 'content.word_count', 'content.capital_ratio', 'content.lower_ratio', 'content.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 1206 | ['__nlp__.about', '__nlp__.about the', '__nlp__.absolute', '__nlp__.absolute nightmare', '__nlp__.absolutely', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t6 features in original data used to generate 1238 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.21 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.69s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1439, Val Rows: 360\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ...\n",
      "\tFitting with cpus=6, gpus=0, mem=0.3/17.7 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tFitting with cpus=6, gpus=0, mem=0.3/17.7 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tFitting with cpus=6, gpus=0, mem=1.5/17.7 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tFitting with cpus=6, gpus=0, mem=0.0/17.7 GB\n",
      "No improvement since epoch 4: early stopping\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tFitting with cpus=6, gpus=0\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting with cpus=6, gpus=0, mem=0.0/17.7 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.31s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tFitting with cpus=6, gpus=0, mem=1.0/17.7 GB\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=12, gpus=0, mem=0.0/17.7 GB\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.98s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 53351.3 rows/s (360 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (360 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/jef/repos/rating-evaluation/AutogluonModels/ag-20260131_005049\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=\"type\").fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "783c0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = predictor.predict(df_test.drop(columns=[\"type\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e33c62d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1707    Negative\n",
       "2189    Positive\n",
       "789     Negative\n",
       "140     Positive\n",
       "775     Positive\n",
       "Name: type, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce7bf944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1707    Negative\n",
       "2189    Positive\n",
       "789     Negative\n",
       "140     Positive\n",
       "775     Positive\n",
       "Name: type, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48c723a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>0.861364</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>0.861364</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.886524</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.025160</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.112879</td>\n",
       "      <td>0.109317</td>\n",
       "      <td>0.819257</td>\n",
       "      <td>0.112879</td>\n",
       "      <td>0.109317</td>\n",
       "      <td>0.819257</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.116036</td>\n",
       "      <td>0.110259</td>\n",
       "      <td>0.741213</td>\n",
       "      <td>0.116036</td>\n",
       "      <td>0.110259</td>\n",
       "      <td>0.741213</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.116723</td>\n",
       "      <td>0.111848</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.116723</td>\n",
       "      <td>0.111848</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.117492</td>\n",
       "      <td>0.111526</td>\n",
       "      <td>0.754551</td>\n",
       "      <td>0.117492</td>\n",
       "      <td>0.111526</td>\n",
       "      <td>0.754551</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>1.077009</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>1.077009</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>0.702559</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>0.702559</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.533757</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.533757</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.007928</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>1.310218</td>\n",
       "      <td>0.007928</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>1.310218</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>1.467018</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>1.467018</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0               XGBoost    1.000000        1.0    accuracy        0.010309   \n",
       "1       NeuralNetFastAI    1.000000        1.0    accuracy        0.011504   \n",
       "2   WeightedEnsemble_L2    1.000000        1.0    accuracy        0.012513   \n",
       "3        ExtraTreesGini    1.000000        1.0    accuracy        0.112879   \n",
       "4      RandomForestEntr    1.000000        1.0    accuracy        0.116036   \n",
       "5        ExtraTreesEntr    1.000000        1.0    accuracy        0.116723   \n",
       "6      RandomForestGini    1.000000        1.0    accuracy        0.117492   \n",
       "7         LightGBMLarge    0.997778        1.0    accuracy        0.004012   \n",
       "8            LightGBMXT    0.997778        1.0    accuracy        0.004064   \n",
       "9              LightGBM    0.997778        1.0    accuracy        0.004419   \n",
       "10       NeuralNetTorch    0.997778        1.0    accuracy        0.007928   \n",
       "11             CatBoost    0.997778        1.0    accuracy        0.017301   \n",
       "\n",
       "    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.004686  0.640777                 0.010309                0.004686   \n",
       "1        0.006367  0.861364                 0.011504                0.006367   \n",
       "2        0.006748  0.886524                 0.001009                0.000381   \n",
       "3        0.109317  0.819257                 0.112879                0.109317   \n",
       "4        0.110259  0.741213                 0.116036                0.110259   \n",
       "5        0.111848  0.742081                 0.116723                0.111848   \n",
       "6        0.111526  0.754551                 0.117492                0.111526   \n",
       "7        0.002876  1.077009                 0.004012                0.002876   \n",
       "8        0.004075  0.702559                 0.004064                0.004075   \n",
       "9        0.003048  0.533757                 0.004419                0.003048   \n",
       "10       0.006906  1.310218                 0.007928                0.006906   \n",
       "11       0.016356  1.467018                 0.017301                0.016356   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.640777            1       True          9  \n",
       "1            0.861364            1       True          8  \n",
       "2            0.025160            2       True         12  \n",
       "3            0.819257            1       True          6  \n",
       "4            0.741213            1       True          4  \n",
       "5            0.742081            1       True          7  \n",
       "6            0.754551            1       True          3  \n",
       "7            1.077009            1       True         11  \n",
       "8            0.702559            1       True          1  \n",
       "9            0.533757            1       True          2  \n",
       "10           1.310218            1       True         10  \n",
       "11           1.467018            1       True          5  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9f82a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jef/repos/rating-evaluation/AutogluonModels/ag-20260131_005049'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36c7814e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jef/repos/rating-evaluation/AutogluonModels/ag-20260131_005049/ensemble_model.png'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.plot_ensemble_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75926ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'binary'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.problem_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e4b2fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('category', [])                    :    3 | ['product_name', 'product_category', 'review_size']\n",
      "('category', ['text_as_category'])  :    2 | ['content', 'review']\n",
      "('int', [])                         :    1 | ['stars']\n",
      "('int', ['binned', 'text_special']) :   26 | ['content.char_count', 'content.word_count', 'content.capital_ratio', 'content.lower_ratio', 'content.special_ratio', ...]\n",
      "('int', ['text_ngram'])             : 1206 | ['__nlp__.about', '__nlp__.about the', '__nlp__.absolute', '__nlp__.absolute nightmare', '__nlp__.absolutely', ...]\n"
     ]
    }
   ],
   "source": [
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ecc8253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>review_size</th>\n",
       "      <th>content</th>\n",
       "      <th>review</th>\n",
       "      <th>content.char_count</th>\n",
       "      <th>content.word_count</th>\n",
       "      <th>content.capital_ratio</th>\n",
       "      <th>content.lower_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>__nlp__.worth the</th>\n",
       "      <th>__nlp__.would</th>\n",
       "      <th>__nlp__.would be</th>\n",
       "      <th>__nlp__.would not</th>\n",
       "      <th>__nlp__.wouldn</th>\n",
       "      <th>__nlp__.yet</th>\n",
       "      <th>__nlp__.you</th>\n",
       "      <th>__nlp__.you get</th>\n",
       "      <th>__nlp__.you re</th>\n",
       "      <th>__nlp__._total_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars product_name product_category review_size content review  \\\n",
       "1707      2           64                5           2      10    NaN   \n",
       "2189      4            6                3           1      32    NaN   \n",
       "789       2           91                7           0      21    NaN   \n",
       "140       5           47                0           1      24    NaN   \n",
       "775       5           64                5           1      22    NaN   \n",
       "\n",
       "      content.char_count  content.word_count  content.capital_ratio  \\\n",
       "1707                   5                   2                      2   \n",
       "2189                   0                   0                      9   \n",
       "789                    1                   0                      1   \n",
       "140                    2                   1                      8   \n",
       "775                    5                   2                      7   \n",
       "\n",
       "      content.lower_ratio  ...  __nlp__.worth the  __nlp__.would  \\\n",
       "1707                    6  ...                  0              0   \n",
       "2189                    0  ...                  0              0   \n",
       "789                     4  ...                  0              0   \n",
       "140                     0  ...                  0              0   \n",
       "775                     2  ...                  0              0   \n",
       "\n",
       "      __nlp__.would be  __nlp__.would not  __nlp__.wouldn  __nlp__.yet  \\\n",
       "1707                 0                  0               0            0   \n",
       "2189                 0                  0               0            0   \n",
       "789                  0                  0               0            0   \n",
       "140                  0                  0               0            0   \n",
       "775                  0                  0               0            0   \n",
       "\n",
       "      __nlp__.you  __nlp__.you get  __nlp__.you re  __nlp__._total_  \n",
       "1707            0                0               0               52  \n",
       "2189            0                0               0               69  \n",
       "789             0                0               0               28  \n",
       "140             0                0               0               49  \n",
       "775             0                0               0               68  \n",
       "\n",
       "[5 rows x 1238 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.transform_features(df_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c59d40cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 6 features using 450 rows with 5 shuffle sets...\n",
      "\t2.08s\t= Expected runtime (0.42s per shuffle set)\n",
      "\t1.32s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <td>0.494222</td>\n",
       "      <td>0.010135</td>\n",
       "      <td>2.120925e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.515090</td>\n",
       "      <td>0.473354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>4.219163e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006046</td>\n",
       "      <td>0.001954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content</th>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>8.890390e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>-0.001617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_name</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_category</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_size</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance    stddev       p_value  n  p99_high   p99_low\n",
       "stars               0.494222  0.010135  2.120925e-08  5  0.515090  0.473354\n",
       "review              0.004000  0.000994  4.219163e-04  5  0.006046  0.001954\n",
       "content             0.000889  0.001217  8.890390e-02  5  0.003395 -0.001617\n",
       "product_name        0.000000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
       "product_category    0.000000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
       "review_size         0.000000  0.000000  5.000000e-01  5  0.000000  0.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45f0e9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L2'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd3acd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0,\n",
       " 'balanced_accuracy': np.float64(1.0),\n",
       " 'mcc': 1.0,\n",
       " 'roc_auc': np.float64(1.0),\n",
       " 'f1': 1.0,\n",
       " 'precision': 1.0,\n",
       " 'recall': 1.0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rating-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
